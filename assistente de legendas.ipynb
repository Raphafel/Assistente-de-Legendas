{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnY_tDFM9lZr",
        "outputId": "0cfec359-63f3-4ab4-a150-0141391a96cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.15.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "koYd7nH3-HUk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n"
      ],
      "metadata": {
        "id": "ttwUCDbo_PFB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "form  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmH4r-JD_u_Y",
        "outputId": "b600177f-97de-4004-d717-d9a83b36e152"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gemini-2.0-flash\"\n",
        "\n",
        "resposta = client.models.generate_content(model=model, contents=\n",
        "                                          \"Quem √© a empresa por tr√°s dos modelos Gemini?\")"
      ],
      "metadata": {
        "id": "QvdyUVhEAHjl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cj7Yc6vaA1JF",
        "outputId": "9d1f9c00-da08-4db7-c29a-1814f79b97c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A empresa por tr√°s dos modelos Gemini √© o **Google**. Mais especificamente, o Google AI e o Google DeepMind trabalharam juntos no desenvolvimento do Gemini.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model=model)\n",
        "\n",
        "resposta = chat.send_message(\"Oi tudo bem?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ANq1ZsiwBbFz",
        "outputId": "1501ec4d-a8b1-4c9f-edc1-197c55e195d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tudo bem por aqui! üòä Como posso te ajudar hoje?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction = \"\"\"\n",
        "    Voc√™ √© um assistente criativo especializado em gerar sugest√µes para legendas de redes sociais,\n",
        "    como Instagram. Sua tarefa √© receber uma frase ou ideia base do usu√°rio e sugerir\n",
        "    legendas curtas e inspiradoras, baseadas em trechos de m√∫sicas famosas (de diversos g√™neros)\n",
        "    e frases de fil√≥sofos importantes.\n",
        "\n",
        "    Formate suas respostas como sugest√µes de legendas, indicando a fonte (M√∫sica ou Fil√≥sofo).\n",
        "    Tente dar 2 a 3 sugest√µes por vez.\n",
        "    Seja direto e focado em legendas.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=model, config=chat_config)\n",
        "\n",
        "print(\"Ol√°! Meu nome √© Noir, sou seu Assistente de Legendas Po√©ticas e Filos√≥ficas!\")\n",
        "print(\"Digite sua ideia ou frase base para a legenda (ou 'fim' para sair).\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "prompt = input (\"Minha ideia para legenda: \")\n",
        "\n",
        "while prompt.lower() != \"fim\": # Usamos .lower() para aceitar 'fim' ou 'FIM'\n",
        "    # Agora, enviamos a ideia do usu√°rio para o Gemini atrav√©s do chat\n",
        "    # O Gemini vai usar a instru√ß√£o que demos l√° em cima para gerar as sugest√µes\n",
        "    resposta = chat.send_message(f\"Ideia base: {prompt}\") # Usamos um f-string para incluir a ideia no prompt\n",
        "\n",
        "    print(\"\\nSugest√µes de Legendas:\")\n",
        "    print(resposta.text) # Mostra a resposta do Gemini com as sugest√µes\n",
        "    print(\"-\" * 30) # Desenha outra linha\n",
        "\n",
        "    prompt = input (\"Minha ideia para legenda: \") # Pede a pr√≥xima ideia\n",
        "\n",
        "print(\"Ok, encerrando o Assistente de Legendas. At√© a pr√≥xima!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqoNzUkyCLjD",
        "outputId": "cfe518dd-7e15-46bc-d2e6-2418fe507b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ol√°! Meu nome √© Noir, sou seu Assistente de Legendas Po√©ticas e Filos√≥ficas!\n",
            "Digite sua ideia ou frase base para a legenda (ou 'fim' para sair).\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Conhe√ßa o Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}